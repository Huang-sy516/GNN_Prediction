{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbea400e-6617-441c-96d8-0b66f49c11c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GCN...\n",
      "Epoch: 000, Loss: 1.9624, Train Acc: 0.6214, Val Acc: 0.3380, Test Acc: 0.3820\n",
      "Epoch: 001, Loss: 1.8509, Train Acc: 0.7429, Val Acc: 0.4620, Test Acc: 0.4840\n",
      "Epoch: 002, Loss: 1.7288, Train Acc: 0.8071, Val Acc: 0.5000, Test Acc: 0.5180\n",
      "Epoch: 003, Loss: 1.5787, Train Acc: 0.8000, Val Acc: 0.5120, Test Acc: 0.5030\n",
      "Epoch: 004, Loss: 1.4589, Train Acc: 0.8071, Val Acc: 0.5060, Test Acc: 0.5070\n",
      "Epoch: 005, Loss: 1.2983, Train Acc: 0.8143, Val Acc: 0.5240, Test Acc: 0.5140\n",
      "Epoch: 006, Loss: 1.1849, Train Acc: 0.8571, Val Acc: 0.5420, Test Acc: 0.5430\n",
      "Epoch: 007, Loss: 1.0986, Train Acc: 0.8714, Val Acc: 0.5820, Test Acc: 0.5820\n",
      "Epoch: 008, Loss: 0.9332, Train Acc: 0.9143, Val Acc: 0.6260, Test Acc: 0.6230\n",
      "Epoch: 009, Loss: 0.8674, Train Acc: 0.9357, Val Acc: 0.6740, Test Acc: 0.6810\n",
      "Epoch: 010, Loss: 0.7500, Train Acc: 0.9500, Val Acc: 0.7160, Test Acc: 0.7300\n",
      "Epoch: 011, Loss: 0.7055, Train Acc: 0.9714, Val Acc: 0.7380, Test Acc: 0.7540\n",
      "Epoch: 012, Loss: 0.5670, Train Acc: 0.9786, Val Acc: 0.7520, Test Acc: 0.7750\n",
      "Epoch: 013, Loss: 0.5440, Train Acc: 0.9857, Val Acc: 0.7640, Test Acc: 0.7860\n",
      "Epoch: 014, Loss: 0.4837, Train Acc: 0.9857, Val Acc: 0.7780, Test Acc: 0.7990\n",
      "Epoch: 015, Loss: 0.4144, Train Acc: 0.9929, Val Acc: 0.7820, Test Acc: 0.8070\n",
      "Epoch: 016, Loss: 0.4089, Train Acc: 1.0000, Val Acc: 0.7880, Test Acc: 0.8050\n",
      "Epoch: 017, Loss: 0.3449, Train Acc: 1.0000, Val Acc: 0.7920, Test Acc: 0.8090\n",
      "Epoch: 018, Loss: 0.3109, Train Acc: 1.0000, Val Acc: 0.7960, Test Acc: 0.8110\n",
      "Epoch: 019, Loss: 0.2451, Train Acc: 1.0000, Val Acc: 0.7920, Test Acc: 0.8060\n",
      "Epoch: 020, Loss: 0.2536, Train Acc: 1.0000, Val Acc: 0.7920, Test Acc: 0.8070\n",
      "Epoch: 021, Loss: 0.1880, Train Acc: 1.0000, Val Acc: 0.7900, Test Acc: 0.8070\n",
      "Epoch: 022, Loss: 0.2132, Train Acc: 1.0000, Val Acc: 0.7900, Test Acc: 0.8080\n",
      "Epoch: 023, Loss: 0.1810, Train Acc: 1.0000, Val Acc: 0.7920, Test Acc: 0.8070\n",
      "Epoch: 024, Loss: 0.1745, Train Acc: 1.0000, Val Acc: 0.7920, Test Acc: 0.8050\n",
      "Epoch: 025, Loss: 0.1567, Train Acc: 1.0000, Val Acc: 0.7860, Test Acc: 0.8100\n",
      "Epoch: 026, Loss: 0.1610, Train Acc: 1.0000, Val Acc: 0.7840, Test Acc: 0.8090\n",
      "Epoch: 027, Loss: 0.1386, Train Acc: 1.0000, Val Acc: 0.7780, Test Acc: 0.8070\n",
      "Epoch: 028, Loss: 0.1154, Train Acc: 1.0000, Val Acc: 0.7780, Test Acc: 0.8080\n",
      "Early stopping triggered\n",
      "Final Test Accuracy for GCN: 0.8080\n",
      "--------------------------------------------------\n",
      "Running GAT...\n",
      "Epoch: 000, Loss: 1.9742, Train Acc: 0.7571, Val Acc: 0.5080, Test Acc: 0.5130\n",
      "Epoch: 001, Loss: 1.5744, Train Acc: 0.8571, Val Acc: 0.6460, Test Acc: 0.6300\n",
      "Epoch: 002, Loss: 1.1904, Train Acc: 0.9643, Val Acc: 0.7580, Test Acc: 0.7620\n",
      "Epoch: 003, Loss: 1.0039, Train Acc: 0.9714, Val Acc: 0.7840, Test Acc: 0.7940\n",
      "Epoch: 004, Loss: 0.7715, Train Acc: 0.9857, Val Acc: 0.8040, Test Acc: 0.8080\n",
      "Epoch: 005, Loss: 0.7648, Train Acc: 0.9929, Val Acc: 0.8040, Test Acc: 0.8120\n",
      "Epoch: 006, Loss: 0.6691, Train Acc: 0.9929, Val Acc: 0.8000, Test Acc: 0.8090\n",
      "Epoch: 007, Loss: 0.5495, Train Acc: 0.9929, Val Acc: 0.7760, Test Acc: 0.8060\n",
      "Epoch: 008, Loss: 0.5810, Train Acc: 0.9857, Val Acc: 0.7700, Test Acc: 0.8000\n",
      "Epoch: 009, Loss: 0.5824, Train Acc: 0.9857, Val Acc: 0.7600, Test Acc: 0.7870\n",
      "Epoch: 010, Loss: 0.5316, Train Acc: 0.9857, Val Acc: 0.7540, Test Acc: 0.7800\n",
      "Epoch: 011, Loss: 0.5431, Train Acc: 0.9857, Val Acc: 0.7500, Test Acc: 0.7720\n",
      "Epoch: 012, Loss: 0.4874, Train Acc: 0.9857, Val Acc: 0.7520, Test Acc: 0.7690\n",
      "Epoch: 013, Loss: 0.4350, Train Acc: 0.9929, Val Acc: 0.7400, Test Acc: 0.7700\n",
      "Epoch: 014, Loss: 0.3531, Train Acc: 1.0000, Val Acc: 0.7360, Test Acc: 0.7640\n",
      "Early stopping triggered\n",
      "Final Test Accuracy for GAT: 0.7640\n",
      "--------------------------------------------------\n",
      "Running GraphSAGE...\n",
      "Epoch: 000, Loss: 1.9617, Train Acc: 0.5500, Val Acc: 0.3560, Test Acc: 0.3510\n",
      "Epoch: 001, Loss: 1.8300, Train Acc: 0.8500, Val Acc: 0.5440, Test Acc: 0.5420\n",
      "Epoch: 002, Loss: 1.6214, Train Acc: 0.9286, Val Acc: 0.6020, Test Acc: 0.6060\n",
      "Epoch: 003, Loss: 1.4082, Train Acc: 0.9500, Val Acc: 0.6280, Test Acc: 0.6280\n",
      "Epoch: 004, Loss: 1.1726, Train Acc: 0.9786, Val Acc: 0.6620, Test Acc: 0.6660\n",
      "Epoch: 005, Loss: 0.9510, Train Acc: 0.9857, Val Acc: 0.7260, Test Acc: 0.6910\n",
      "Epoch: 006, Loss: 0.7551, Train Acc: 1.0000, Val Acc: 0.7360, Test Acc: 0.7210\n",
      "Epoch: 007, Loss: 0.6411, Train Acc: 1.0000, Val Acc: 0.7580, Test Acc: 0.7400\n",
      "Epoch: 008, Loss: 0.5216, Train Acc: 1.0000, Val Acc: 0.7540, Test Acc: 0.7400\n",
      "Epoch: 009, Loss: 0.4030, Train Acc: 1.0000, Val Acc: 0.7420, Test Acc: 0.7460\n",
      "Epoch: 010, Loss: 0.3404, Train Acc: 1.0000, Val Acc: 0.7380, Test Acc: 0.7400\n",
      "Epoch: 011, Loss: 0.2994, Train Acc: 1.0000, Val Acc: 0.7300, Test Acc: 0.7370\n",
      "Epoch: 012, Loss: 0.1932, Train Acc: 1.0000, Val Acc: 0.7300, Test Acc: 0.7390\n",
      "Epoch: 013, Loss: 0.2198, Train Acc: 1.0000, Val Acc: 0.7400, Test Acc: 0.7500\n",
      "Epoch: 014, Loss: 0.1226, Train Acc: 1.0000, Val Acc: 0.7420, Test Acc: 0.7590\n",
      "Epoch: 015, Loss: 0.1480, Train Acc: 1.0000, Val Acc: 0.7520, Test Acc: 0.7710\n",
      "Epoch: 016, Loss: 0.1243, Train Acc: 1.0000, Val Acc: 0.7520, Test Acc: 0.7760\n",
      "Epoch: 017, Loss: 0.0882, Train Acc: 1.0000, Val Acc: 0.7620, Test Acc: 0.7790\n",
      "Epoch: 018, Loss: 0.1089, Train Acc: 1.0000, Val Acc: 0.7640, Test Acc: 0.7840\n",
      "Epoch: 019, Loss: 0.0861, Train Acc: 1.0000, Val Acc: 0.7680, Test Acc: 0.7880\n",
      "Epoch: 020, Loss: 0.0622, Train Acc: 1.0000, Val Acc: 0.7700, Test Acc: 0.7900\n",
      "Epoch: 021, Loss: 0.0498, Train Acc: 1.0000, Val Acc: 0.7720, Test Acc: 0.7880\n",
      "Epoch: 022, Loss: 0.0887, Train Acc: 1.0000, Val Acc: 0.7700, Test Acc: 0.7870\n",
      "Epoch: 023, Loss: 0.0418, Train Acc: 1.0000, Val Acc: 0.7700, Test Acc: 0.7880\n",
      "Epoch: 024, Loss: 0.0331, Train Acc: 1.0000, Val Acc: 0.7720, Test Acc: 0.7900\n",
      "Epoch: 025, Loss: 0.0714, Train Acc: 1.0000, Val Acc: 0.7700, Test Acc: 0.7820\n",
      "Epoch: 026, Loss: 0.0376, Train Acc: 1.0000, Val Acc: 0.7640, Test Acc: 0.7800\n",
      "Epoch: 027, Loss: 0.0440, Train Acc: 1.0000, Val Acc: 0.7580, Test Acc: 0.7810\n",
      "Epoch: 028, Loss: 0.0205, Train Acc: 1.0000, Val Acc: 0.7580, Test Acc: 0.7770\n",
      "Epoch: 029, Loss: 0.0289, Train Acc: 1.0000, Val Acc: 0.7540, Test Acc: 0.7770\n",
      "Epoch: 030, Loss: 0.0459, Train Acc: 1.0000, Val Acc: 0.7540, Test Acc: 0.7780\n",
      "Epoch: 031, Loss: 0.0291, Train Acc: 1.0000, Val Acc: 0.7520, Test Acc: 0.7730\n",
      "Early stopping triggered\n",
      "Final Test Accuracy for GraphSAGE: 0.7730\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# 加载Cora数据集\n",
    "dataset = Planetoid(root='D:\\\\temp\\\\Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "# 定义模型\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, activation=F.relu):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.activation(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, activation=F.elu):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(dataset.num_node_features, 16, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(16 * 8, dataset.num_classes, heads=1, concat=False, dropout=0.6)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.activation(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, activation=F.relu):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = SAGEConv(16, dataset.num_classes)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.activation(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# 训练模型\n",
    "def train(model, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# 测试模型\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    logits, accs = model(data), []\n",
    "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "# 运行和评估每个模型\n",
    "models = {\n",
    "    'GCN': GCN(),\n",
    "    'GAT': GAT(),\n",
    "    'GraphSAGE': GraphSAGE()\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    scheduler = StepLR(optimizer, step_size=50, gamma=0.5)  # 每50个epoch将学习率减半\n",
    "    best_val_acc = 0\n",
    "    patience = 10  # 早停的耐心值\n",
    "    patience_counter = 0\n",
    "\n",
    "    print(f'Running {model_name}...')\n",
    "\n",
    "    for epoch in range(200):\n",
    "        loss = train(model, optimizer)\n",
    "        train_acc, val_acc, test_acc = test(model)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "        \n",
    "        # 早停判断\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    \n",
    "    print(f'Final Test Accuracy for {model_name}: {test_acc:.4f}')\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4c1a2-c858-4481-95fa-a2fac258d186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
